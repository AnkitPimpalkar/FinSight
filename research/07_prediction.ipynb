{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f25d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/finance_ml/entity/config_entity.py\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPredictionConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    input_data_path: Path\n",
    "    predictions_file_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config/config.yaml\n",
    "\n",
    "model_prediction:\n",
    "  root_dir: artifacts/model_prediction\n",
    "  trained_model_path: artifacts/model_training/lstm_model.keras\n",
    "  input_data_path: artifacts/data_transformation/raw_data.csv # Path to the input data for prediction\n",
    "  predictions_file_name: predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a56516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/finance_ml/config/configuration.py\n",
    "\n",
    "from finance_ml.constants import *\n",
    "from finance_ml.utils.common import read_yaml, create_directories\n",
    "from finance_ml.entity.config_entity import DataIngestionConfig, DataTransformationConfig, ModelTrainingConfig, ModelTrainingParams, ModelEvaluationConfig, ModelPredictionConfig # Import ModelPredictionConfig\n",
    "import os\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_prediction_config(self) -> ModelPredictionConfig: # Add the new method\n",
    "        config = self.config.model_prediction\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_prediction_config = ModelPredictionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            trained_model_path=Path(config.trained_model_path), # Ensure Path type\n",
    "            input_data_path=Path(config.input_data_path), # Ensure Path type\n",
    "            predictions_file_name=config.predictions_file_name\n",
    "        )\n",
    "\n",
    "        return model_prediction_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/finance_ml/component/model_prediction.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler # Assuming you used MinMaxScaler in data transformation\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming these imports are available from previous steps\n",
    "from finance_ml.entity.config_entity import ModelPredictionConfig\n",
    "# Assuming a save_csv utility function exists\n",
    "from finance_ml.utils.common import save_csv # Assuming a save_csv utility exists\n",
    "\n",
    "class ModelPrediction:\n",
    "    def __init__(self, config: ModelPredictionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def predict(self):\n",
    "        # Load the trained model\n",
    "        model = keras.models.load_model(self.config.trained_model_path)\n",
    "\n",
    "        # Load the input data for prediction\n",
    "        # Assuming the input data is a CSV with a 'close' column, similar to training data\n",
    "        data = pd.read_csv(self.config.input_data_path)\n",
    "\n",
    "        # --- Data Preprocessing for Prediction ---\n",
    "        # This should mirror the preprocessing steps used for the training data\n",
    "        # Assuming the prediction is based on the 'close' price and a sliding window approach (like in rorWPcAaocTq)\n",
    "\n",
    "        # Select the 'close' column\n",
    "        stock_close = data.filter([\"close\"])\n",
    "        dataset = stock_close.values # Convert to numpy array\n",
    "\n",
    "        # Apply the same scaler used for training data\n",
    "        # IMPORTANT: You need to save and load the *fitted* scaler from the data transformation stage.\n",
    "        # For this example, I'll create a new scaler, but in a real project, load the saved scaler.\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1)) # Use MinMaxScaler if that was used in transformation\n",
    "        scaled_data = scaler.fit_transform(dataset) # Fit and transform - in a real project, just transform using loaded scaler\n",
    "\n",
    "        # Create the input sequence for prediction (sliding window)\n",
    "        # Assuming the prediction is for the next step based on the last 'time_steps' data points\n",
    "        # Need to determine the 'time_steps' used during training (e.g., 60)\n",
    "        time_steps = 60 # Assuming 60 based on the training example\n",
    "\n",
    "        # Use the last 'time_steps' data points from the scaled data\n",
    "        X_predict = scaled_data[-time_steps:].reshape(1, time_steps, 1) # Reshape for LSTM: (samples, time_steps, features)\n",
    "\n",
    "\n",
    "        # Make the prediction\n",
    "        predicted_price_scaled = model.predict(X_predict)\n",
    "\n",
    "        # Inverse transform the prediction to get the actual price\n",
    "        predicted_price = scaler.inverse_transform(predicted_price_scaled)\n",
    "\n",
    "        # --- Save the Prediction ---\n",
    "        # You might want to save the prediction along with the corresponding date or index\n",
    "        # For simplicity, let's just save the predicted price\n",
    "        predictions_df = pd.DataFrame(predicted_price, columns=['predicted_close_price'])\n",
    "\n",
    "        predictions_file_path = Path(self.config.root_dir) / self.config.predictions_file_name\n",
    "        save_csv(predictions_file_path, predictions_df) # Assuming a save_csv utility function exists\n",
    "\n",
    "        print(f\"Predicted next closing price: {predicted_price[0][0]}\")\n",
    "        print(f\"Predictions saved to: {predictions_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/finance_ml/pipeline/stage_05_model_prediction.py\n",
    "\n",
    "# Assuming ConfigurationManager and ModelPrediction are importable from src.finance_ml\n",
    "from src.finance_ml.config.configuration import ConfigurationManager\n",
    "from src.finance_ml.component.model_prediction import ModelPrediction\n",
    "# Assuming logger is configured elsewhere or imported from src.finance_ml\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__) # Use the configured logger\n",
    "\n",
    "\n",
    "STAGE_NAME = \"Model Prediction stage\"\n",
    "\n",
    "class ModelPredictionPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        try:\n",
    "            logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n",
    "            # Get configuration\n",
    "            config_manager = ConfigurationManager()\n",
    "            model_prediction_config = config_manager.get_model_prediction_config()\n",
    "\n",
    "            # Perform model prediction\n",
    "            model_prediction = ModelPrediction(config=model_prediction_config)\n",
    "            model_prediction.predict()\n",
    "\n",
    "            logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e\n",
    "\n",
    "# Example of how to run this stage\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Assuming logging is configured at the entry point of the application\n",
    "        # or configure it here if running this script directly for testing\n",
    "        # logging.basicConfig(level=logging.INFO, format='[%(asctime)s: %(levelname)s: %(name)s: %(message)s]')\n",
    "\n",
    "        obj = ModelPredictionPipeline()\n",
    "        obj.main()\n",
    "    except Exception as e:\n",
    "        logger.exception(e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
